{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14823614-b416-4a45-b48b-60205235e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_version: 1.12.1\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "from torch import nn, Tensor\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model import TransformerModel, generate_square_subsequent_mask\n",
    "# from data_utils import data_process, batchify, get_batch\n",
    "# from train import train_epoch, evaluate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"torch_version: {torch.__version__}\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae4da6-0835-4d9a-9ad3-4d1b78590733",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c68323-68aa-4c5e-87a8-a0d9a34c0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "train_iter = WikiText2(split=\"train\")\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "idx2word = {i: x for i, x in enumerate(vocab.get_itos())}\n",
    "def to_sentence(x):\n",
    "    return \" \".join([idx2word[int(idx)] for idx in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee63ab-760f-4c83-be89-1158eed54017",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef08a6b-b4ce-4993-8cfc-f4a4d9efdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)\n",
    "emsize = 200\n",
    "d_hid = 200\n",
    "nlayers = 2\n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "\n",
    "model =  TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "model.load_state_dict(torch.load(\"../weights\", map_location=torch.device('cpu')))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69251e-23be-4b36-860a-d71f917ac0ea",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b116c0d-3c41-48a8-a064-ed601523bd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt =  \"there was a white horse on a beach. Steve and his friends had\"\n",
    "prompt = \"Cheney addresses possibility of White House run after crushing loss to\"\n",
    "prompt = \"None of them noticed a large, tawny owl flutter past your mother\"\n",
    "x = torch.tensor(vocab(tokenizer(prompt))).unsqueeze(-1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a53189e0-6f32-413c-8db0-233ce0489e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none of them noticed a large , tawny owl <unk> past your mother ,\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk>\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> ,\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and <unk>\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and <unk> ,\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and <unk> , and\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and <unk> , and <unk>\n",
      "none of them noticed a large , tawny owl <unk> past your mother , and <unk> , and <unk> , and <unk> ,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    mask = generate_square_subsequent_mask(x.size(0))\n",
    "    output = model(x, mask)\n",
    "\n",
    "    y = output.argmax(dim = -1).squeeze()\n",
    "    x = torch.concat((x,  y[-1:].unsqueeze(-1)))\n",
    "    print(to_sentence(x[:, 0]))\n",
    "\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
