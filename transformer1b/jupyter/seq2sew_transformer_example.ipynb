{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d966a41-b2a0-431d-a053-2d4610b5ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For colab\n",
    "\n",
    "# !pip install torchtext\n",
    "# !pip install torchdatasets\n",
    "# !pip intstall spacy\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3ce0be-fec6-4dc4-9d64-6dc3f7f38909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c117c-2c29-4c21-95cb-08b508952ef2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362ec5ed-5e18-4a4d-a368-a2ae7a2a21d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Multi30k with train split ...\n",
      "src:  torch.Size([2, 15])\n",
      "tgt:  torch.Size([2, 14]) \n",
      "\n",
      "<bos> Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche . <eos> \n",
      " <bos> Two young , White males are outside near many bushes . <eos> <pad> \n",
      "\n",
      "<bos> Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem . <eos> <pad> <pad> <pad> <pad> <pad> \n",
      " <bos> Several men in hard hats are operating a giant pulley system . <eos> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "\n",
    "from typing import Iterable, List\n",
    "from data_utils import Dataset\n",
    "\n",
    "d = Dataset()\n",
    "\n",
    "B = 2\n",
    "for src, tgt in d.get_dataloader(B):\n",
    "    print(\"src: \", src.shape)\n",
    "    print(\"tgt: \", tgt.shape, \"\\n\")\n",
    "    for j in range(B):\n",
    "        src_tokens = list(src[j, :].detach().numpy())\n",
    "        tgt_tokens = list(tgt[j, :].detach().numpy())\n",
    "        src_sentence = \" \".join(d.src_vocab.lookup_tokens(src_tokens))\n",
    "        tgt_sentence = \" \".join(d.tgt_vocab.lookup_tokens(tgt_tokens))\n",
    "        print(src_sentence, \"\\n\", tgt_sentence, \"\\n\")\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69634f-f4ea-43b3-8c34-7b12e93a76f3",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "from torch import nn\n",
    "from transformer import Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7137e26e-828f-4af2-b8f9-e64ea0ed073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Seq2SeqTransformer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "B = 128\n",
    "D, Dff  = 8, 8\n",
    "n_heads = 2\n",
    "l_enc, l_dec = 1, 1\n",
    "\n",
    "transformer = Seq2SeqTransformer(l_enc, l_dec, D, n_heads, d.src_vocab_size, d.tgt_vocab_size, Dff).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index = d._PAD_IDX)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5d345-74ac-4446-83a4-2aacd2c08bfa",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e175da-5226-4ba9-b8b7-fe251ae46f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Multi30k with valid split ...\n",
      "Epoch: 1, Train loss: 9.314, Val loss: 9.251, Epoch time: 58.467\n",
      "Epoch: 2, Train loss: 9.198, Val loss: 9.114, Epoch time: 56.275\n",
      "Epoch: 3, Train loss: 9.060, Val loss: 8.970, Epoch time: 57.277\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "from utils import create_masks\n",
    "from train import train_epoch, evaluate\n",
    "from typing import Callable\n",
    "\n",
    "# train_epoch(d, transformer, optimizer, loss_fn, B, device=device, log_interval = 5, early_stop = 20)    \n",
    "# evaluate(d, transformer, loss_fn, B, device)\n",
    "\n",
    "def train( d: Dataset, model: nn.Module, optimizer: Optimizer, loss_fn: Callable[[Tensor, Tensor], Tensor], B: int, epochs: int, device: torch.device):\n",
    "    for e in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(d, transformer, optimizer, loss_fn, B, device=device, log_interval = 0, early_stop = 100)    \n",
    "        val_loss = evaluate(d, transformer, loss_fn, B, device)\n",
    "        \n",
    "        msg = f\"Epoch: {e}, Train loss: {train_loss:<.3f}, Val loss: {val_loss:<.3f}, \" \n",
    "        msg += f\"Epoch time: {time.time() - start_time:.3f}\"\n",
    "        print(msg)\n",
    "        \n",
    "epochs = 3\n",
    "train(d, transformer, optimizer, loss_fn, B, epochs, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519bcec-1dd5-48ed-8459-22370ce8731a",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582126aa-cbfe-4914-8eaf-42e5cdfa16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:\n",
      "Eine Gruppe von Menschen steht vor einem Iglu\n",
      "\n",
      "translation:\n",
      "<bos> einer einer einer einer einer einer einer einer einer einer einer einer einer einer\n"
     ]
    }
   ],
   "source": [
    "from utils import generate_square_subsequent_mask\n",
    "\n",
    "def greedy_decode(model: nn.Module, src: Tensor, src_mask: Tensor, max_len: int, start_symbol: int, device: torch.device):\n",
    "    src, src_mask = src.to(device), src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    # memory = memory.to(device)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    \n",
    "    for i in range(max_len-1):\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(1)).type(torch.bool).to(device)\n",
    "        \n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        \n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        \n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        \n",
    "        if next_word == d._EOS_IDX:\n",
    "            break\n",
    "        \n",
    "    return ys\n",
    "        \n",
    "def translate(model: nn.Module, d: Dataset, src_sentence: str, device: torch.device) -> str:    \n",
    "    src = d.src_transform(src_sentence).view(1, -1)\n",
    "    ns = src.shape[1]\n",
    "    src_mask = torch.zeros(ns, ns).type(torch.bool)\n",
    "\n",
    "    max_len = ns + 5\n",
    "    start_symbol = d._BOS_IDX\n",
    "\n",
    "    ys = greedy_decode(model, src, src_mask, max_len, start_symbol, device)    \n",
    "    ys = list(ys.squeeze().cpu().numpy())\n",
    "    return \" \".join(d.src_vocab.lookup_tokens(ys))\n",
    "\n",
    "src_sentence = \"Eine Gruppe von Menschen steht vor einem Iglu\"\n",
    "tgt_sentence = translate(transformer, d, src_sentence, device)\n",
    "print(f\"sentence:\\n{src_sentence}\\n\\ntranslation:\\n{tgt_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
