# Transformer from scratch

 * [x] scaled dot product attention
 * [x] multi head attention
 * [x] positional encoding
 * [x] encoder
 * [ ] decoder
 * [x] encoder only example
 * [ ] encoder decoder example
